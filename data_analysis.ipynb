{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(17)\n",
    "import random\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from config import Config\n",
    "\n",
    "config = Config()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensors.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    "os.rename('data/train', 'data/train_transforms_1')\n",
    "os.rename('data/val', 'data/val_transforms_1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(r'data/train')\n",
    "shutil.rmtree(r'data/val')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [],
   "source": [
    "os.mkdir(r'data/train')\n",
    "os.mkdir(r'data/val')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "# Save train set and validation set in different folders\n",
    "for label in train:\n",
    "    path_to_rome = os.path.join(r'data/train', label_to_rome[label])\n",
    "    os.mkdir(path_to_rome)\n",
    "    for i, img in enumerate(train[label]):\n",
    "        save_image(img, os.path.join(path_to_rome, f'{i}.png'))\n",
    "\n",
    "for label in val:\n",
    "    path_to_rome = os.path.join(r'data/val', label_to_rome[label])\n",
    "    os.mkdir(path_to_rome)\n",
    "    for i, img in enumerate(val[label]):\n",
    "        save_image(img, os.path.join(path_to_rome, f'{i}.png'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transformations and Augmentations\n",
    "Save 4 transformed versions for each image in the training set (only 4, so we stay below a total of 10,000 images as requested)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "transformations = torch.nn.Sequential(\n",
    "    transforms.RandomRotation(30, fill=1),\n",
    "    transforms.GaussianBlur(random.randrange(1, 10, 2)),\n",
    "    transforms.RandomResizedCrop(64, scale=(0.6, 1))\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [],
   "source": [
    "transformations = torch.nn.Sequential(\n",
    "    transforms.RandomRotation(15, fill=1),\n",
    "    transforms.GaussianBlur(random.randrange(1, 10, 2)),\n",
    "    transforms.RandomResizedCrop(64, scale=(0.9, 1))\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [],
   "source": [
    "# Save transformed images\n",
    "for label in train:\n",
    "    path_to_rome = os.path.join(r'data/train', label_to_rome[label])\n",
    "    for i, img in enumerate(train[label]):\n",
    "        for j in range(4):\n",
    "            save_image(transformations(img), os.path.join(path_to_rome, f'{i}_t{j}.png'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [],
   "source": [
    "# Original data\n",
    "train_dir = os.path.join(\"data\", \"train\")\n",
    "val_dir = os.path.join(\"data\", \"val\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [
    "# Resize the samples and transform them into tensors\n",
    "data_transforms = transforms.Compose([transforms.Resize([64, 64]), transforms.ToTensor()])\n",
    "\n",
    "# Create a pytorch dataset from a directory of images\n",
    "train_dataset = datasets.ImageFolder(train_dir, data_transforms)\n",
    "val_dataset = datasets.ImageFolder(val_dir, data_transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset ImageFolder\n    Number of datapoints: 8290\n    Root location: data/train\n    StandardTransform\nTransform: Compose(\n               Resize(size=[64, 64], interpolation=bilinear, max_size=None, antialias=None)\n               ToTensor()\n           )"
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset ImageFolder\n    Number of datapoints: 419\n    Root location: data/val\n    StandardTransform\nTransform: Compose(\n               Resize(size=[64, 64], interpolation=bilinear, max_size=None, antialias=None)\n               ToTensor()\n           )"
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}